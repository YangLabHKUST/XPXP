{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style \n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import matplotlib\n",
    "import copy\n",
    "import glob as gb\n",
    "import scipy.stats as st\n",
    "import time\n",
    "from pandas_plink import read_plink1_bin\n",
    "from scipy.stats.stats import pearsonr\n",
    "import sys\n",
    "sys.path.append('../XPXP/src')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "def worker(x):\n",
    "    return os.system(x)\n",
    "pool=Pool(processes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plink_file1 = '../simulation/genodata/eas_merge_qc2_330k_noMHC'\n",
    "plink_file2 = '../simulation/genodata/ukb_qc2_60k_330k_noMHC'\n",
    "\n",
    "ref1_info = pd.read_csv(plink_file1+'.bim',sep='\\t',header=None)\n",
    "ref1_info.columns = ['chr','SNP','cm','bp','A1','A2']\n",
    "ref2_info = pd.read_csv(plink_file2+'.bim',sep='\\t',header=None)\n",
    "ref2_info.columns = ['chr','SNP','cm','bp','A1','A2']\n",
    "ref1_info = ref1_info.reset_index()\n",
    "ref2_info = ref2_info.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = ReadPlink(plink_file1,ref1_info,np.int8)\n",
    "X2 = ReadPlink(plink_file2,ref2_info,np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32921, 330485), (60000, 330485))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape, X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly selected 12000 samples\n",
    "x1_idx = np.load('../simulation/genodata/eas_merge_qc2_12k_idx.npy')\n",
    "x1_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X1[x1_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_stan = X1.astype(np.float32)\n",
    "X1_stan = (X1_stan-X1_stan.mean(axis=0))/X1_stan.var(axis=0)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_stan = X2.astype(np.float32)\n",
    "X2_stan = (X2_stan-X2_stan.mean(axis=0))/X2_stan.var(axis=0)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = X1[-2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 330485), (60000, 330485), (2000, 330485))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_stan.shape, X2_stan.shape, X1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitiaCorrMatrix(corr,nump):\n",
    "    tmp = np.eye(nump)\n",
    "    tmp[np.triu_indices(nump,1)]=corr\n",
    "    return tmp\n",
    "\n",
    "def GetBestPT(df,tp):\n",
    "    init = 0\n",
    "    initi = 0\n",
    "    for i in df.iteritems():\n",
    "        cor = pearsonr(i[1].values,tp)[0]\n",
    "        if cor>init:\n",
    "            init = cor\n",
    "            initi = i[0]\n",
    "    return initi,init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XPXP, SMTpred, LDpred-inf, P+T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simulation(rep,tansgc):\n",
    "    share_heri = 0.48\n",
    "    corrG = corrE = 0\n",
    "    phenos = ['A']\n",
    "    nump = len(phenos)\n",
    "    EAS_pheno = BBJ_include_pheno = [_+'-EAS' for _ in phenos]\n",
    "    EUR_pheno = UKB_include_pheno = [_+'-EUR' for _ in phenos]\n",
    "    columns = BBJ_include_pheno+UKB_include_pheno\n",
    "\n",
    "    heri = np.array([share_heri for _ in range(len(columns))]) # shared heritability\n",
    "    true_heri = np.array([0.5 for _ in range(len(columns))])\n",
    "    heri_df = pd.DataFrame(heri.reshape(1,-1),columns=columns)\n",
    "    true_heri_df = pd.DataFrame(true_heri.reshape(1,-1),columns=columns)\n",
    "\n",
    "    corr_trans = np.full((nump,nump),corrG*tansgc)\n",
    "    corr_trans[np.diag_indices(nump)] = tansgc\n",
    "    corr_eas = corr_eur = InitiaCorrMatrix(corrG,nump)\n",
    "    corr_env_eas = corr_env_eur = InitiaCorrMatrix(corrE,nump)\n",
    "\n",
    "    genetic_corr = np.concatenate((np.concatenate((corr_eas,corr_trans),axis=1),np.concatenate(\\\n",
    "                                                    (np.zeros((nump,nump)),corr_eur),axis=1)),axis=0)\n",
    "    genetic_corr = genetic_corr.T + genetic_corr - np.diag(np.diag(genetic_corr))\n",
    "    env_corr = np.concatenate((np.concatenate((corr_env_eas,np.zeros((nump,nump))),axis=1),np.concatenate(\\\n",
    "                                                    (np.zeros((nump,nump)),corr_env_eur),axis=1)),axis=0)\n",
    "    env_corr = env_corr.T + env_corr - np.diag(np.diag(env_corr))\n",
    "    genetic_cov = np.zeros((nump*2,nump*2))\n",
    "    for i in range(nump*2):\n",
    "        for j in range(nump*2):\n",
    "            genetic_cov[i,j] = genetic_corr[i,j]*(heri[i]*heri[j])**.5\n",
    "    env_cov = np.zeros((nump*2,nump*2))\n",
    "    for i in range(nump*2):\n",
    "        for j in range(nump*2):\n",
    "            env_cov[i,j] = env_corr[i,j]*((1-true_heri[i])*(1-true_heri[j]))**.5\n",
    "    genetic_corr_df = pd.DataFrame(genetic_corr,columns=columns,index=columns)\n",
    "    genetic_cov_df = pd.DataFrame(genetic_cov,columns=columns,index=columns)\n",
    "    env_corr_df = pd.DataFrame(env_corr,columns=columns,index=columns)\n",
    "    env_cov_df = pd.DataFrame(env_cov,columns=columns,index=columns)\n",
    "    #print(genetic_cov_df)\n",
    "    #print(env_cov_df)\n",
    "    \n",
    "    n1,n2,m,meff,mleff = X1.shape[0],X2.shape[0],X1.shape[1],30000,30\n",
    "    beta = np.load('../simulation/fix_beta/SingleTrait_beta_TG{}.npy'.format(tansgc))\n",
    "    \n",
    "    eps1 = np.random.multivariate_normal(np.zeros(nump),env_cov_df.values[:nump,:nump],n1)\n",
    "    eps2 = np.random.multivariate_normal(np.zeros(nump),env_cov_df.values[nump:,nump:],n2)\n",
    "\n",
    "    for i,p in enumerate(columns):\n",
    "        ref1_info[p] = beta[:,i]\n",
    "\n",
    "    if not os.path.exists('../simulation/reps/{}'.format(rep)):\n",
    "        os.mkdir('../simulation/reps/{}'.format(rep))\n",
    "    ref1_info[['chr','SNP','cm','bp','A1','A2']+columns].to_csv(\\\n",
    "        '../simulation/reps/{}/effect_size.txt'.format(rep),sep='\\t',index=None)\n",
    "    \n",
    "    y1_phenos = {}\n",
    "    y1 = X1_stan.dot(beta[:,:nump])+eps1\n",
    "    for i,p in enumerate(phenos):\n",
    "        tmp = y1[:,i]\n",
    "        tmp = (tmp-tmp.mean())/tmp.var()**.5\n",
    "        y1_phenos[p] = tmp\n",
    "    y2 = X2_stan.dot(beta[:,nump:])+eps2\n",
    "    y2_phenos = {}\n",
    "    for i,p in enumerate(phenos):\n",
    "        tmp = y2[:,i]\n",
    "        tmp = (tmp-tmp.mean())/tmp.var()**.5\n",
    "        y2_phenos[p] = tmp\n",
    "        \n",
    "    fam1 = pd.read_csv(plink_file1+'.fam',delim_whitespace=True,header=None)\n",
    "    fam1 = fam1[[0,1]]\n",
    "    fam1.columns = ['FID','IID']\n",
    "    fam1 = fam1.loc[x1_idx]\n",
    "    fam1 = fam1.reset_index()\n",
    "    fam1 = fam1.drop('index',axis=1)\n",
    "    for i,p in enumerate(phenos):\n",
    "        fam1[p] = y1_phenos[p]\n",
    "\n",
    "    fam2 = pd.read_csv(plink_file2+'.fam',delim_whitespace=True,header=None)\n",
    "    fam2 = fam2[[0,1]]\n",
    "    fam2.columns = ['FID','IID']\n",
    "    for i,p in enumerate(phenos):\n",
    "        fam2[p] = y2_phenos[p]\n",
    "\n",
    "    fam1_train = fam1.loc[:9999,:] ##\n",
    "    fam1_test = fam1.loc[10000:,:] ##\n",
    "    fam1_train.shape, fam1_test.shape\n",
    "    fam1_train.to_csv('../simulation/reps/{}/fam1_train.txt'.format(rep),sep='\\t',index=None)\n",
    "    fam1_test.to_csv('../simulation/reps/{}/fam1_test.txt'.format(rep),sep='\\t',index=None)\n",
    "    fam2.to_csv('../simulation/reps/{}/fam2_90k.txt'.format(rep),sep='\\t',index=None)\n",
    "    fam2.loc[:10000,:].to_csv('../simulation/reps/{}/fam2_20k.txt'.format(rep),sep='\\t',index=None)\n",
    "    fam2.loc[:20000,:].to_csv('../simulation/reps/{}/fam2_40k.txt'.format(rep),sep='\\t',index=None)\n",
    "    fam2.loc[:40000,:].to_csv('../simulation/reps/{}/fam2_60k.txt'.format(rep),sep='\\t',index=None)\n",
    "\n",
    "    \n",
    "    os.system('/import/home/share/xiaojs/software/plink2 --linear \\\n",
    "    --bfile ../simulation/genodata/eas_merge_qc2_330k_noMHC \\\n",
    "    --pheno ../simulation/reps/{0}/fam1_train.txt \\\n",
    "    --read-freq ../simulation/genodata/eas_merge_qc2_330k_freq.frq \\\n",
    "    --no-parents --no-sex \\\n",
    "    --out ../simulation/reps/{0}/eas'.format(rep))\n",
    "    for i in [20,40,60,90]:\n",
    "        os.system('/import/home/share/xiaojs/software/plink2 --linear \\\n",
    "        --bfile ../simulation/genodata/ukb_qc2_90k_330k_noMHC \\\n",
    "        --pheno ../simulation/reps/{0}/fam2_{1}k.txt \\\n",
    "        --read-freq ../simulation/genodata/eas_merge_qc2_330k_freq.frq \\\n",
    "        --no-parents --no-sex \\\n",
    "        --out ../simulation/reps/{0}/eur_{1}k'.format(rep,i))\n",
    "        \n",
    "    for p in phenos:\n",
    "        df = pd.read_csv('../simulation/reps/{0}/eas.{1}.glm.linear'.format(rep,p),sep='\\t')\n",
    "        df['Z'] = df.apply(lambda x:x['BETA']/x['SE'], axis=1)\n",
    "        df = df[['ID','OBS_CT','ALT','REF','Z']]\n",
    "        df.columns = ['SNP','N','A1','A2','Z']\n",
    "        df.to_csv('../simulation/reps/{0}/{1}-EAS.txt'.format(rep,p),sep='\\t',index=None)\n",
    "        for i in [20,40,60,90]:\n",
    "            df = pd.read_csv('../simulation/reps/{0}/eur_{1}k.{2}.glm.linear'.format(rep,i,p),sep='\\t')\n",
    "            df['Z'] = df.apply(lambda x:x['BETA']/x['SE'], axis=1)\n",
    "            df = df[['ID','OBS_CT','ALT','REF','Z']]\n",
    "            df.columns = ['SNP','N','A1','A2','Z']\n",
    "            df.to_csv('../simulation/reps/{0}/{1}-EUR_{2}k.txt'.format(rep,p,i),sep='\\t',index=None)\n",
    "    \n",
    "    \n",
    "    ### Genetic Correlation\n",
    "    \n",
    "    f_eas = ['../simulation/reps/{0}/{1}-EAS.txt'.format(rep,p) for p in phenos]\n",
    "    f_eur = ['../simulation/reps/{0}/{1}-EUR_90k.txt'.format(rep,p) for p in phenos]\n",
    "    com = 'python ../XPXP/src/TransGC.py \\\n",
    "    --save ../simulation/reps/{0}/{1}_{2} \\\n",
    "    --use_snp ../simulation/genodata/used_SNPs.txt \\\n",
    "    --ref_files /home/share/UKB/ld_ref_2k/height_affy_ldpred_ref_2000_noMHC_300kSNPs,/home/share/UKB/ld_ref_2k/height_ukb_ldpred_ref_2000_noMHC_300kSNPs \\\n",
    "    --covar_files , \\\n",
    "    --sumst_files {3},{4}'\n",
    "    coms = []\n",
    "    for i,peas in enumerate(BBJ_include_pheno):\n",
    "        for j,peur in enumerate(UKB_include_pheno):\n",
    "            coms.append(com.format(rep,peas,peur,f_eas[i],f_eur[j]))\n",
    "\n",
    "    output = pool.map(worker,coms)\n",
    "\n",
    "    ldsc_com_heri = 'conda run -n ldsc python ldsc.py --h2 {0} --ref-ld-chr {1} --w-ld-chr {1} --out ../simulation/reps/{2}/{3}.log'\n",
    "    ldsc_com_rg = 'conda run -n ldsc python ldsc.py --rg {0} --ref-ld-chr {1} --w-ld-chr {1} --out ../simulation/reps/{2}/{3}_{4}.log'\n",
    "    for i,peas in enumerate(BBJ_include_pheno):\n",
    "        os.system(ldsc_com_heri.format(f_eas[i],./XPXP_demo/eas_ldscores/,rep,peas))    \n",
    "    for i,peas in enumerate(BBJ_include_pheno):\n",
    "        for j,peur in enumerate(BBJ_include_pheno[(i+1):]):\n",
    "            os.system(ldsc_com_rg.format(f_eas[i]+','+f_eas[j+i+1],./XPXP_demo/eas_ldscores/,rep,peas,peur))\n",
    "    \n",
    "    for i,peas in enumerate(UKB_include_pheno):\n",
    "        os.system(ldsc_com_heri.format(f_eur[i],./XPXP_demo/eur_ldscores/,rep,peas))    \n",
    "    for i,peas in enumerate(UKB_include_pheno):\n",
    "        for j,peur in enumerate(UKB_include_pheno[(i+1):]):\n",
    "            os.system(ldsc_com_rg.format(f_eur[i]+','+f_eur[j+i+1],./XPXP_demo/eur_ldscores/,rep,peas,peur))\n",
    "    \n",
    "\n",
    "    eas_eur_cov = np.zeros((len(BBJ_include_pheno),len(UKB_include_pheno)))\n",
    "    eas_eur_corr = np.zeros((len(BBJ_include_pheno),len(UKB_include_pheno)))\n",
    "    eas_heri = np.zeros(len(BBJ_include_pheno))\n",
    "    eur_heri = np.zeros(len(UKB_include_pheno))\n",
    "\n",
    "    for i,peas in enumerate(BBJ_include_pheno):\n",
    "        for j,peur in enumerate(UKB_include_pheno):\n",
    "            fc = '../simulation/reps/{}/{}_{}.log'.format(rep,peas,peur)\n",
    "            corr = open(fc).readlines()[-2].split()[-1]\n",
    "            cov = open(fc).readlines()[-2].split()[-2]\n",
    "            eas_heri[i] = open(fc).readlines()[-2].split()[-4]\n",
    "            eur_heri[j] = open(fc).readlines()[-2].split()[-3]\n",
    "            eas_eur_cov[i,j] = cov\n",
    "            eas_eur_corr[i,j] = corr\n",
    "    eas_eur_cov_df = pd.DataFrame(eas_eur_cov,index=BBJ_include_pheno,columns=UKB_include_pheno)\n",
    "    eas_eur_corr_df = pd.DataFrame(eas_eur_corr,index=BBJ_include_pheno,columns=UKB_include_pheno)\n",
    "    eas_eur_cov_e_df = pd.DataFrame(np.zeros((len(BBJ_include_pheno),len(UKB_include_pheno))),index=BBJ_include_pheno,columns=UKB_include_pheno)\n",
    "    eur_heri_df = pd.DataFrame(eur_heri,index=UKB_include_pheno,columns=['heri'])\n",
    "    eas_heri_df = pd.DataFrame(eas_heri,index=BBJ_include_pheno,columns=['heri'])\n",
    "\n",
    "    eas_eas_cov = np.zeros((len(BBJ_include_pheno),len(BBJ_include_pheno)))\n",
    "    eas_eas_cov_e = np.zeros((len(BBJ_include_pheno),len(BBJ_include_pheno)))\n",
    "\n",
    "    for i,peas in enumerate(BBJ_include_pheno):\n",
    "        for j,peas2 in enumerate((BBJ_include_pheno)[i+1:]):\n",
    "            fc = '../simulation/reps/{}/{}_{}.log'.format(rep,peas,peas2)\n",
    "            for ln,line in enumerate(open(fc).readlines()):\n",
    "                if 'gencov:' in line:\n",
    "                    eas_eas_cov[i,i+1+j] = float(line.split()[-2])\n",
    "                    break\n",
    "            eas_eas_cov_e[i,i+1+j] = float(open(fc).readlines()[ln+2].split()[-2])-eas_eas_cov[i,i+1+j]\n",
    "        eas_eas_cov[i,i] = eas_heri_df.loc[peas].values[0]\n",
    "        eas_eas_cov_e[i,i] = 1-eas_heri_df.loc[peas].values[0]\n",
    "    eas_eas_cov = eas_eas_cov+eas_eas_cov.T-np.diag(np.diag(eas_eas_cov))\n",
    "    eas_eas_cov_e = eas_eas_cov_e+eas_eas_cov_e.T-np.diag(np.diag(eas_eas_cov_e))\n",
    "\n",
    "    eas_eas_cov_df = pd.DataFrame(eas_eas_cov,index=EAS_pheno,columns=EAS_pheno)\n",
    "    eas_eas_cov_e_df = pd.DataFrame(eas_eas_cov_e,index=EAS_pheno,columns=EAS_pheno)\n",
    "\n",
    "    eur_eur_cov = np.zeros((len(UKB_include_pheno),len(UKB_include_pheno)))\n",
    "    eur_eur_cov_e = np.zeros((len(UKB_include_pheno),len(UKB_include_pheno)))\n",
    "\n",
    "    for i,peas in enumerate(UKB_include_pheno):\n",
    "        for j,peas2 in enumerate(UKB_include_pheno[i+1:]):\n",
    "            fc = '../simulation/reps/{}/{}_{}.log'.format(rep,peas,peas2)\n",
    "            for ln,line in enumerate(open(fc).readlines()):\n",
    "                if 'gencov:' in line:\n",
    "                    eur_eur_cov[i,i+1+j] = float(line.split()[-2])\n",
    "                    break\n",
    "            eur_eur_cov_e[i,i+1+j] = float(open(fc).readlines()[ln+2].split()[-2])-eur_eur_cov[i,i+1+j]\n",
    "        eur_eur_cov[i,i] = eur_heri_df.loc[peas].values[0]\n",
    "        eur_eur_cov_e[i,i] = 1-eur_heri_df.loc[peas].values[0]\n",
    "    eur_eur_cov = eur_eur_cov+eur_eur_cov.T-np.diag(np.diag(eur_eur_cov))\n",
    "    eur_eur_cov_e = eur_eur_cov_e+eur_eur_cov_e.T-np.diag(np.diag(eur_eur_cov_e))\n",
    "\n",
    "    eur_eur_cov_df = pd.DataFrame(eur_eur_cov,index=EUR_pheno,columns=EUR_pheno)\n",
    "    eur_eur_cov_e_df = pd.DataFrame(eur_eur_cov_e,index=EUR_pheno,columns=EUR_pheno)\n",
    "\n",
    "    cov_df = pd.concat((pd.concat((eas_eas_cov_df,eas_eur_cov_df),axis=1),pd.concat((eas_eur_cov_df.T,eur_eur_cov_df),axis=1)),axis=0)\n",
    "    cov_e_df = pd.concat((pd.concat((eas_eas_cov_e_df,eas_eur_cov_e_df),axis=1),pd.concat((eas_eur_cov_e_df.T,eur_eur_cov_e_df),axis=1)),axis=0)\n",
    "\n",
    "    for c1 in columns:\n",
    "        for c2 in columns:\n",
    "            if c1==c2:\n",
    "                continue\n",
    "            else:\n",
    "                if cov_df.loc[c1,c2] > 0.95*(cov_df.loc[c1,c1]*cov_df.loc[c2,c2])**.5:\n",
    "                    cov_df.loc[c1,c2] = 0.95*(cov_df.loc[c1,c1]*cov_df.loc[c2,c2])**.5\n",
    "                elif cov_df.loc[c1,c2] < -0.95*(cov_df.loc[c1,c1]*cov_df.loc[c2,c2])**.5:\n",
    "                    cov_df.loc[c1,c2] = -0.95*(cov_df.loc[c1,c1]*cov_df.loc[c2,c2])**.5\n",
    "                else:\n",
    "                    pass\n",
    "                if cov_e_df.loc[c1,c2] > 0.95*(cov_e_df.loc[c1,c1]*cov_e_df.loc[c2,c2])**.5:\n",
    "                    cov_e_df.loc[c1,c2] = 0.95*(cov_e_df.loc[c1,c1]*cov_e_df.loc[c2,c2])**.5\n",
    "                elif cov_e_df.loc[c1,c2] < -0.95*(cov_e_df.loc[c1,c1]*cov_e_df.loc[c2,c2])**.5:\n",
    "                    cov_e_df.loc[c1,c2] = -0.95*(cov_e_df.loc[c1,c1]*cov_e_df.loc[c2,c2])**.5\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "    corr_df = cov_to_corr(cov_df)\n",
    "    corr_df.to_csv('../simulation/reps/{}/gcorr_C6.csv'.format(rep))\n",
    "    cov_df.to_csv('../simulation/reps/{}/gcov_C6.csv'.format(rep))\n",
    "    cov_e_df.to_csv('../simulation/reps/{}/ecov_C6.csv'.format(rep))\n",
    "\n",
    "\n",
    "    ### XPXP    \n",
    "    sumsfiles = ['../simulation/reps/{0}/{1}-EAS.txt'.format(rep,p) for p in phenos]        \n",
    "    os.system('python ../XPXP/src/XPXP.py \\\n",
    "    --fix_effect_trait A-EAS \\\n",
    "    --return_LDpredinf \\\n",
    "    --num_threads 32 \\\n",
    "    --save ../simulation/reps/{0}/MT-PM-EAS-p1.csv \\\n",
    "    --gc_file ../simulation/reps/{0}/gcov_C6.csv \\\n",
    "    --ec_file ../simulation/reps/{0}/ecov_C6.csv \\\n",
    "    --sumst_files {1} \\\n",
    "    --sumst_ss {2}+ \\\n",
    "    --ref_files /home/share/UKB/ld_ref_2k/height_affy_ldpred_ref_2000_noMHC_300kSNPs,/home/share/UKB/ld_ref_2k/height_ukb_ldpred_ref_2000_noMHC_300kSNPs \\\n",
    "    --use_snp ../simulation/genodata/used_SNPs.txt \\\n",
    "    --ld_block_file  /home/share/xiaojs/database/prs/EAS_fourier_ls-all.bed'.format(rep,','.join(sumsfiles),','.join(EAS_pheno)))\n",
    "    \n",
    "    \n",
    "    com = 'plink \\\n",
    "        --bfile ../simulation/genodata/eas_merge_qc2_330k_noMHC \\\n",
    "        --score ../simulation/reps/{0}/MT-PM-EAS-p1.csv 2 4 {1} header sum \\\n",
    "        --out ../simulation/reps/{0}/{2}'\n",
    "\n",
    "    coms = []\n",
    "    score_file = '../simulation/reps/{0}/MT-PM-EAS-p1.csv'.format(rep)\n",
    "    header = open(score_file,'r').readline().strip().split('\\t')\n",
    "    for p in EAS_pheno:\n",
    "        col = 1+header.index('{}-mu'.format(p))\n",
    "        coms.append(com.format(rep,col,p))\n",
    "    output = pool.map(worker,coms)\n",
    "    \n",
    "    \n",
    "    corr_df = pd.read_csv('../simulation/reps/{}/gcorr_C6.csv'.format(rep), index_col=0)\n",
    "    cov_df = pd.read_csv('../simulation/reps/{}/gcov_C6.csv'.format(rep), index_col=0)\n",
    "    cov_e_df = pd.read_csv('../simulation/reps/{}/ecov_C6.csv'.format(rep), index_col=0)\n",
    "    \n",
    "    n2s = [10,20,40,60] # true sample size\n",
    "    for idx,i in enumerate([20,40,60,90]):\n",
    "        ### XPXP        \n",
    "        sumsfiles = ['../simulation/reps/{0}/{1}-EAS.txt'.format(rep,p) for p in phenos]+\\\n",
    "            ['../simulation/reps/{0}/{1}-EUR_{2}k.txt'.format(rep,p,i) for p in phenos]\n",
    "        os.system('python ../XPXP/src/XPXP.py \\\n",
    "        --num_threads 32 \\\n",
    "        --fix_effect_trait A-EAS \\\n",
    "        --return_LDpredinf \\\n",
    "        --save ../simulation/reps/{0}/MT-PM-All-p1-{1}k.csv \\\n",
    "        --gc_file ../simulation/reps/{0}/gcov_C6.csv \\\n",
    "        --ec_file ../simulation/reps/{0}/ecov_C6.csv \\\n",
    "        --sumst_files {2} \\\n",
    "        --sumst_ss {3}+{4} \\\n",
    "        --ref_files /home/share/UKB/ld_ref_2k/height_affy_ldpred_ref_2000_noMHC_300kSNPs,/home/share/UKB/ld_ref_2k/height_ukb_ldpred_ref_2000_noMHC_300kSNPs \\\n",
    "        --use_snp ../simulation/genodata/used_SNPs.txt \\\n",
    "        --ld_block_file  /home/share/xiaojs/database/prs/EAS_fourier_ls-all.bed'.format(rep,i,\n",
    "                                                                                       ','.join(sumsfiles),\n",
    "                                                                                       ','.join(EAS_pheno),\n",
    "                                                                                       ','.join(EUR_pheno)))\n",
    "        \n",
    "        \n",
    "        com = 'plink \\\n",
    "        --bfile ../simulation/genodata/eas_merge_qc2_330k_noMHC \\\n",
    "        --score ../simulation/reps/{0}/MT-PM-All-p1-{1}k.csv 2 4 {2} header sum \\\n",
    "        --out ../simulation/reps/{0}/{3}-{1}k'\n",
    "\n",
    "        coms = []\n",
    "        score_file = '../simulation/reps/{0}/MT-PM-All-p1-{1}k.csv'.format(rep,i)\n",
    "        header = open(score_file,'r').readline().strip().split('\\t')\n",
    "        for p in UKB_include_pheno:\n",
    "            col = 1+header.index('{}-mu'.format(p))\n",
    "            coms.append(com.format(rep,i,col,p))\n",
    "        output = pool.map(worker,coms)\n",
    "        \n",
    "        ### smtpred\n",
    "        with open('../simulation/reps/{0}/ns-p1-{1}k.txt'.format(rep,i), 'w') as f:\n",
    "            for p in BBJ_include_pheno:\n",
    "                f.write(p+'\\t'+str(10000)+'\\n')\n",
    "            for p in UKB_include_pheno:\n",
    "                f.write(p+'-{}k\\t'.format(i)+str(n2s[idx]*1000)+'\\n')\n",
    "            f.close()\n",
    "        with open('../simulation/reps/{0}/h2s-p1-{1}k.txt'.format(rep,i), 'w') as f:\n",
    "            for p in BBJ_include_pheno:\n",
    "                f.write(p+'\\t'+str(cov_df.loc[p,p])+'\\n')\n",
    "            for p in UKB_include_pheno:\n",
    "                f.write(p+'-{}k\\t'.format(i)+str(cov_df.loc[p,p])+'\\n')\n",
    "            f.close()\n",
    "        all_include_pheno = BBJ_include_pheno+UKB_include_pheno\n",
    "        with open('../simulation/reps/{0}/rgs-p1-{1}k.txt'.format(rep,i), 'w') as f:\n",
    "            for idx,p in enumerate(all_include_pheno):\n",
    "                for p2 in all_include_pheno[idx+1:]:\n",
    "                    if 'EUR' in p:\n",
    "                        p_name = p+'-{}k'.format(i)\n",
    "                    else:\n",
    "                        p_name = p\n",
    "                    if 'EUR' in p2:\n",
    "                        p2_name = p2+'-{}k'.format(i)\n",
    "                    else:\n",
    "                        p2_name = p2\n",
    "                    f.write(p_name+'\\t'+p2_name+'\\t'+str(corr_df.loc[p,p2])+'\\n')\n",
    "            f.close()\n",
    "        \n",
    "        sumsfiles = ['../simulation/reps/{0}/{1}-EAS.profile'.format(rep,p) for p in phenos]+\\\n",
    "                ['../simulation/reps/{0}/{1}-EUR-{2}k.profile'.format(rep,p,i) for p in phenos]\n",
    "        os.system('conda run -n ldsc python /import/home/share/xiaojs/software/smtpred/smtpred.py \\\n",
    "            --h2file ../simulation/reps/{0}/h2s-p1-{1}k.txt \\\n",
    "            --rgfile ../simulation/reps/{0}/rgs-p1-{1}k.txt \\\n",
    "            --nfile ../simulation/reps/{0}/ns-p1-{1}k.txt \\\n",
    "            --scorefiles {2} \\\n",
    "            --out ../simulation/reps/{0}/wMT-SBLUP-All-p1-{1}k \\\n",
    "            --blup'.format(rep,i,' '.join(sumsfiles)))\n",
    "        \n",
    "    ### P+T  \n",
    "    pt_coms = []\n",
    "    pt_coms.append('Rscript pt-method-plink-input.R \\\n",
    "               ../simulation/reps/{0}/eas.A.glm.linear \\\n",
    "               ../simulation/reps/{0}/eas.A.PTpred.txt'.format(rep))\n",
    "    for i in [20,40,60,90]:\n",
    "        pt_coms.append('Rscript pt-method-plink-input.R \\\n",
    "               ../simulation/reps/{0}/eur_{1}k.A.glm.linear \\\n",
    "               ../simulation/reps/{0}/eur_{1}k.A.PTpred.txt'.format(rep,i))\n",
    "    output = pool.map(worker,pt_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tansgc in [0,0.3,0.6]:\n",
    "    for i in range(1,11):\n",
    "        rep = 'v9-p1-TG{}-{}'.format(tansgc,i)\n",
    "        try:\n",
    "            Simulation(rep,tansgc)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRS-CSx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "simu_path = '../simulation/reps/'\n",
    "\n",
    "reformat_com1 = 'python ~/cross-popu/xpxp/reformat_ss_PRScsx.py \\\n",
    "--inp ../simulation/reps/{0}/A-EAS.txt \\n'\n",
    "\n",
    "prscs_com1 = 'python /home/share/xiaojs/software/PRScsx/PRScsx.py \\\n",
    "--ref_dir=/home/share/xiaojs/software/PRScsx/ref_data \\\n",
    "--bim_prefix=../simulation/genodata/eas_merge_qc2_330k_noMHC \\\n",
    "--sst_file=../simulation/reps/{0}/A-EAS.txt.prscsx_format.txt \\\n",
    "--n_gwas=10000 \\\n",
    "--pop=EAS  \\\n",
    "--n_iter=1000 \\\n",
    "--n_burnin=500 \\\n",
    "--phi=1e-2 \\\n",
    "--out_dir=../simulation/reps/{0} \\\n",
    "--out_name=PRScsx \\n\\n'\n",
    "\n",
    "reformat_com2 = 'python ~/cross-popu/xpxp/reformat_ss_PRScsx.py \\\n",
    "--inp ../simulation/reps/{0}/A-EUR_{1}k.txt \\n'\n",
    "\n",
    "prscs_com2 = 'python /home/share/xiaojs/software/PRScsx/PRScsx.py \\\n",
    "--ref_dir=/home/share/xiaojs/software/PRScsx/ref_data \\\n",
    "--bim_prefix=../simulation/genodata/eas_merge_qc2_330k_noMHC \\\n",
    "--sst_file=../simulation/reps/{0}/A-EAS.txt.prscsx_format.txt,../simulation/reps/{0}/A-EUR_{1}k.txt.prscsx_format.txt \\\n",
    "--n_gwas=10000,{2} \\\n",
    "--pop=EAS,EUR  \\\n",
    "--n_iter=1000 \\\n",
    "--n_burnin=500 \\\n",
    "--phi=1e-2 \\\n",
    "--out_dir=../simulation/reps/{0} \\\n",
    "--out_name=PRScsx_{1}k \\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [10000,20000,40000,60000]\n",
    "snames = [20,40,60,90]\n",
    "for j,tgc in enumerate([0,0.3,0.6]):\n",
    "    with open('../xpxp/prscsx/prscsx_{}.sh'.format(tgc), 'w') as f:\n",
    "        f.write('#!/bin/bash \\n\\n')\n",
    "        f.write('set -o pipefail\\nset -exu \\n\\n')\n",
    "        for r in range(1,11):\n",
    "            rep = 'v9-p1-TG{}-{}'.format(tgc,r)\n",
    "            f.write('dt=$(date \"+%d/%m/%Y %H:%M:%S\")\\necho \"$dt\"\\n')\n",
    "            if os.path.exists(simu_path+rep):\n",
    "                f.write('echo '+rep+'\\n\\n')\n",
    "                f.write(reformat_com1.format(rep))\n",
    "                f.write(prscs_com1.format(rep))\n",
    "                for i in range(4):\n",
    "                    f.write('dt=$(date \"+%d/%m/%Y %H:%M:%S\")\\necho \"$dt\"\\n')\n",
    "                    f.write(reformat_com2.format(rep,snames[i]))\n",
    "                    f.write(prscs_com2.format(rep,snames[i],sample_sizes[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDpred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run --net=host -it \\\n",
    "-v ../simulation/reps:/simulation/reps \\\n",
    "-v /home/share/UKB/1kg_ref/maf_0.05:/home/share/UKB/1kg_ref/maf_0.05    \\\n",
    "-v /home/jxiaoae/cross-popu/xpxp/ldpred2.R:/ldpred2.R \\\n",
    "-v ../xpxp/ldpred2:/ldpred2 \\\n",
    "lifebitai/bigsnpr:1.0 /bin/bash\n",
    "                    \n",
    "export OPENBLAS_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(bigsnpr)\n",
    "snp_readBed(\"1000G.EAS.QC.hm3.ind.bed\")\n",
    "snp_readBed(\"1000G.EUR.QC.hm3.ind.bed\")Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "simu_path = '../simulation/reps/'\n",
    "\n",
    "reformat_com1 = 'python ~/cross-popu/xpxp/reformat_ss_ldpred2.py \\\n",
    "--inp ../simulation/reps/{0}/A-EAS.txt \\n'\n",
    "\n",
    "reformat_com2 = 'python ~/cross-popu/xpxp/reformat_ss_ldpred2.py \\\n",
    "--inp ../simulation/reps/{0}/A-EUR_{1}k.txt \\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "snames = [20,40,60,90]\n",
    "with open('../xpxp/ldpred2/ldpred2_format.sh', 'w') as f:\n",
    "    for j,tgc in enumerate([0,0.3,0.6]):\n",
    "        f.write('#!/bin/bash \\n\\n')\n",
    "        f.write('set -o pipefail\\nset -exu \\n\\n')\n",
    "        for r in range(1,11):\n",
    "            rep = 'v9-p1-TG{}-{}'.format(tgc,r)\n",
    "            f.write('dt=$(date \"+%d/%m/%Y %H:%M:%S\")\\necho \"$dt\"\\n')\n",
    "            if os.path.exists(simu_path+rep):\n",
    "                f.write('echo '+rep+'\\n\\n')\n",
    "                f.write(reformat_com1.format(rep))\n",
    "                for i in range(4):\n",
    "                    f.write('dt=$(date \"+%d/%m/%Y %H:%M:%S\")\\necho \"$dt\"\\n')\n",
    "                    f.write(reformat_com2.format(rep,snames[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldpred2_com1 = 'Rscript /ldpred2.R \\\n",
    "/home/share/UKB/1kg_ref/maf_0.05/1000G.EAS.QC.hm3.ind.rds \\\n",
    "../simulation/reps/{0}/{1}-EAS.txt.ldpred2_format.txt \\\n",
    "../simulation/reps/{0}/LDpred2-beta-auto-{1}-EAS.csv  \\n\\n'\n",
    "\n",
    "ldpred2_com2 = 'Rscript /ldpred2.R \\\n",
    "/home/share/UKB/1kg_ref/maf_0.05/1000G.EUR.QC.hm3.ind.rds \\\n",
    "../simulation/reps/{0}/{1}-EUR_{2}k.txt.ldpred2_format.txt \\\n",
    "../simulation/reps/{0}/LDpred2-beta-auto-{1}-EUR_{2}k.csv  \\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snames = [20,40,60,90]\n",
    "with open('../xpxp/ldpred2/ldpred2_run.sh', 'w') as f:\n",
    "    for j,tgc in enumerate([0,0.3,0.6]):\n",
    "        f.write('#!/bin/bash \\n\\n')\n",
    "        f.write('set -o pipefail\\nset -exu \\n\\n')\n",
    "        for r in range(1,11):\n",
    "            rep = 'v9-p1-TG{}-{}'.format(tgc,r)\n",
    "            f.write('dt=$(date \"+%d/%m/%Y %H:%M:%S\")\\necho \"$dt\"\\n')\n",
    "            if os.path.exists(simu_path+rep):\n",
    "                f.write('echo '+rep+'\\n\\n')\n",
    "                f.write(ldpred2_com1.format(rep,'A'))\n",
    "                for i in range(4):\n",
    "                    f.write('dt=$(date \"+%d/%m/%Y %H:%M:%S\")\\necho \"$dt\"\\n')\n",
    "                    f.write(ldpred2_com2.format(rep,'A',snames[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiPRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def LDpred2_score_mean(rep_path):\n",
    "    score = np.array([pd.read_csv(rep_path+'{}.profile'.format(i),delim_whitespace=True)['SCORESUM'].values for i in range(1,6)]).mean(axis=0)\n",
    "    tmp = pd.read_csv(rep_path+'{}.profile'.format(1),delim_whitespace=True)\n",
    "    tmp['SCORESUM'] = score\n",
    "    return tmp\n",
    "\n",
    "def multiPRS(X,y):\n",
    "    clf = LinearRegression()\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='r2')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prscsx_tg_res = []\n",
    "snames = [20,40,60,90]\n",
    "for j,tgc in enumerate([0,0.3]):\n",
    "    prscsx_res_allrep = []\n",
    "    for r in range(1,11):\n",
    "        rep = 'v9-p1-TG{}-{}'.format(tgc,r)\n",
    "        if os.path.exists(simu_path+rep):\n",
    "            prscsx_res = []\n",
    "            pheno = pd.read_csv(simu_path+'{0}/fam1_test.txt'.format(rep),delim_whitespace=True)\n",
    "            rep_path = simu_path+'{0}/LDpred2_EAS_pred_'.format(rep)\n",
    "            tmp = LDpred2_score_mean(rep_path)\n",
    "            tmp = tmp.merge(pheno[['IID','A']])\n",
    "            y = tmp['A'].values\n",
    "            prscsx_res.append(pearsonr(tmp['SCORESUM'],tmp['A'])[0]**2)\n",
    "            for s in [20,40,60,90]:\n",
    "                tmp2 = LDpred2_score_mean(simu_path+'{0}/LDpred2_EUR_{1}k_pred_'.format(rep,s)) \n",
    "                tmp2 = tmp2.merge(pheno[['IID','A']])\n",
    "                X = np.array([tmp['SCORESUM'],tmp2['SCORESUM']]).T\n",
    "                prscsx_res.append(multiPRS(X,y))\n",
    "            prscsx_res_allrep.append(np.array(prscsx_res))\n",
    "    prscsx_res_allrep = np.array(prscsx_res_allrep)\n",
    "    prscsx_tg_res.append(prscsx_res_allrep.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
